# training_pipeline/trainer.py
from __future__ import annotations

import numpy as np
import warnings
from typing import Dict, Any, Tuple

from sklearn.base import clone
from sklearn.exceptions import ConvergenceWarning

# éœéŸ³éƒ¨åˆ†ç„¡é—œç·Šè¦çš„è­¦å‘Šï¼Œä¿ç•™ä½ åŸæœ‰è¼¸å‡ºé¢¨æ ¼
warnings.filterwarnings("ignore", category=ConvergenceWarning)


class Trainer:
    """
    è¨“ç·´å™¨ï¼šé€ä¸€è¨“ç·´ models dict å…§çš„æ¨¡å‹ã€‚
    - ä¿ç•™åŸæœ‰å°å‡ºæ ¼å¼èˆ‡èªæ°£ã€‚
    - å° LightGBM åŠ å…¥å¤šå±¤ç´šã€Œå®‰å…¨åƒæ•¸ã€èˆ‡è³‡æ–™æ¸…ç†ï¼Œé¿å… left_count==0 çš„ Fatalã€‚
    - å…¨ç¨‹ä¸æ”¹ä½ çš„äº’å‹•æ–¹å¼èˆ‡ CLIã€‚
    """

    def __init__(self) -> None:
        pass

    # ===================== Public API =====================
    def train(self, models: Dict[str, Any], X, y) -> Dict[str, Any]:
        fitted = {}
        for name, est in models.items():
            print(f"ğŸ‹ï¸  è¨“ç·´æ¨¡å‹ï¼š{name}")
            fitted[name] = self._fit_one(name, est, X, y)
        return fitted

    # ===================== Internal Helpers =====================
    def _fit_one(self, name: str, est, X, y):
        """
        - çµ±ä¸€å…ˆåšè³‡æ–™å¥æª¢èˆ‡æ¸…ç†ï¼ˆå°æ‰€æœ‰æ¨¡å‹ä¸€è‡´ï¼‰ã€‚
        - å° LGBM é¡å¤–åšå¤šå±¤ç´š fallbackã€‚
        """
        X_pre, y_clean = self._sanitize_xy(X, y)

        # LightGBMï¼šå¥—ç”¨å®‰å…¨è¨“ç·´æµç¨‹
        if self._is_lgbm(est):
            # level 1
            safe_est = self._make_lgb_safe(est, level=1)
            print("ğŸ›¡ï¸  [LGB] ä½¿ç”¨ LightGBM å®‰å…¨åƒæ•¸è¨“ç·´ï¼ˆé¿å…ç©ºå­ç¯€é» Fatalï¼‰")
            try:
                return self._fit_silent(safe_est, X_pre, y_clean)
            except Exception as e1:
                print(f"\nâš ï¸  [LGB] å®‰å…¨åƒæ•¸ä»å¤±æ•—ï¼Œå‡ç´šä¿å®ˆåº¦å¾Œå†è©¦ã€‚éŒ¯èª¤ï¼š{e1}\n")

            # level 2
            safer_est = self._make_lgb_safe(est, level=2)
            try:
                return self._fit_silent(safer_est, X_pre, y_clean)
            except Exception as e2:
                print(f"\nâš ï¸  [LGB] ç¬¬äºŒå±¤ä¿å®ˆåƒæ•¸ä»å¤±æ•—ï¼Œå˜—è©¦æœ€åš´æ ¼æ¨¡å¼ï¼ˆrow-wise + æ›´å° max_binï¼‰ã€‚éŒ¯èª¤ï¼š{e2}\n")

            # level 3ï¼ˆæœ€åš´æ ¼ï¼‰
            safest_est = self._make_lgb_safe(est, level=3)
            try:
                return self._fit_silent(safest_est, X_pre, y_clean)
            except Exception as e3:
                # åˆ°é€™å±¤ä»å¤±æ•—ï¼Œå›æ‹‹ä¾‹å¤–ï¼Œè®“ä¸Šå±¤é¡¯ç¤ºä¸€è‡´çš„ã€Œç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ã€
                raise e3

        # å…¶ä»–æ¨¡å‹ï¼šåŸæ¨£è¨“ç·´
        return self._fit_silent(est, X_pre, y_clean)

    def _fit_silent(self, est, X, y):
        # ç¶­æŒ sklearn é¢¨æ ¼ï¼Œé¿å…é›œè¨Šè¼¸å‡º
        est.fit(X, y)
        return est

    # ===================== LightGBM Utilities =====================
    def _is_lgbm(self, est) -> bool:
        cls = est.__class__.__name__.lower()
        return ("lgbm" in cls) or ("lightgbm" in cls)

    def _make_lgb_safe(self, est, level: int = 1):
        """
        å¤šå±¤ç´šé˜²å‘†è¨­å®šï¼Œåƒ…åœ¨åƒæ•¸å­˜åœ¨æ™‚æ‰è¨­å®šï¼Œä¸æœƒç ´å£ä½ åŸæœ¬å‚³å…¥åƒæ•¸ã€‚
        ç›®æ¨™ï¼šé¿å…ã€Œbest_split_info.left_count == 0ã€çš„ Fatalã€‚
        """
        m = clone(est)
        params = m.get_params()

        def set_if_has(**pairs):
            exist = {k: v for k, v in pairs.items() if k in params}
            if exist:
                m.set_params(**exist)

        # é€šç”¨å®‰å…¨é …ï¼ˆå„å±¤å…±äº«ï¼‰
        # - CPU + æ±ºå®šå¼ + è¡Œç‚ºæ”¶æ–‚
        set_if_has(n_jobs=1)
        if "device_type" in params:
            set_if_has(device_type="cpu")
        elif "device" in params:
            set_if_has(device="cpu")

        # LightGBM sklearn API çš„å¸¸è¦‹éµ
        for k in ("verbosity", "force_col_wise", "deterministic", "zero_as_missing",
                  "feature_pre_filter", "enable_bundle", "max_bin", "min_data_in_bin",
                  "min_data_in_leaf", "min_sum_hessian_in_leaf", "min_gain_to_split",
                  "num_leaves", "bagging_freq", "bagging_fraction",
                  "feature_fraction", "lambda_l1", "lambda_l2", "max_depth"):
            if k not in params:
                params[k] = None  # è®“ set_if_has å¯ä»¥è¾¨è­˜

        # é‡å°é¡åˆ¥ä¸å¹³è¡¡ï¼ˆbinary æ‰ç”Ÿæ•ˆï¼›multiclass å¿½ç•¥ï¼‰
        if "is_unbalance" in params:
            set_if_has(is_unbalance=True)

        # Level 1ï¼šæº«å’Œ
        if level == 1:
            set_if_has(
                verbosity=-1,
                force_col_wise=True,            # column-wise é€šå¸¸è¼ƒç©©
                deterministic=True,
                zero_as_missing=True,
                feature_pre_filter=False,       # é—œé–‰é éæ¿¾ï¼Œé¿å…æ—©æœŸç„¡æ•ˆåˆ†è£‚
                enable_bundle=False,            # é—œé–‰ç‰¹å¾µæ‰“åŒ…
                max_bin=127,                    # é è¨­ 255ï¼Œé™ä½ä¸€åŠ
                min_data_in_bin=5,              # æ¯å€‹ bin è‡³å°‘æ¨£æœ¬æ•¸
                min_data_in_leaf=50,            # è‘‰ç¯€é»æœ€å°‘æ¨£æœ¬æ•¸
                min_sum_hessian_in_leaf=1e-3,   # é¿å… hessian å¤ªå°
                min_gain_to_split=0.0,
                num_leaves=31,
                bagging_freq=0,
                bagging_fraction=1.0,
                feature_fraction=1.0,
                lambda_l1=0.0,
                lambda_l2=0.0,
                max_depth=-1,
            )
            return m

        # Level 2ï¼šä¿å®ˆ
        if level == 2:
            set_if_has(
                verbosity=-1,
                force_col_wise=True,
                deterministic=True,
                zero_as_missing=True,
                feature_pre_filter=False,
                enable_bundle=False,
                max_bin=63,                     # å†ç¸®å°åˆ†ç®±
                min_data_in_bin=15,
                min_data_in_leaf=200,
                min_sum_hessian_in_leaf=1e-2,   # åŠ å¼· hessian ä¸‹é™
                min_gain_to_split=1e-8,
                num_leaves=15,
                bagging_freq=0,
                bagging_fraction=1.0,
                feature_fraction=0.8,           # ç•¥é™ç‰¹å¾µæ¯”ä¾‹
                lambda_l1=1e-3,
                lambda_l2=1e-2,
                max_depth=8,
            )
            return m

        # Level 3ï¼šæœ€åš´æ ¼ï¼ˆä¸”åˆ‡æ› row-wise ç®—æ³•ï¼‰
        if level == 3:
            # æ³¨æ„ï¼šæœ‰äº›ç‰ˆæœ¬ key ç‚º force_row_wiseï¼Œæœ‰äº›æ²’æœ‰ï¼›set_if_has æœƒè‡ªå‹•å¿½ç•¥ä¸å­˜åœ¨çš„éµã€‚
            if "force_row_wise" in params:
                m.set_params(force_row_wise=True)

            set_if_has(
                verbosity=-1,
                deterministic=True,
                zero_as_missing=True,
                feature_pre_filter=False,
                enable_bundle=False,
                max_bin=31,                     # æœ€å°åŒ–åˆ†ç®±æ•¸ï¼Œé™ä½ã€Œç©ºå­ç¯€é»ã€æ©Ÿç‡
                min_data_in_bin=30,
                min_data_in_leaf=1000,          # è‘‰ç¯€é»æ›´å¤§ï¼Œä¿è­‰é›™å´æœ‰äºº
                min_sum_hessian_in_leaf=5e-2,   # æ˜é¡¯æé«˜ hessian ä¸‹é™
                min_gain_to_split=0.0,
                num_leaves=7,
                bagging_freq=0,
                bagging_fraction=1.0,
                feature_fraction=0.6,
                lambda_l1=1e-2,
                lambda_l2=1e-1,
                max_depth=6,
            )
            return m

        return m

    # ===================== Data Sanitation =====================
    def _sanitize_xy(self, X, y) -> Tuple[np.ndarray, np.ndarray]:
        """
        - è½‰ç‚º float32 / int64ï¼ˆè¦– y è€Œå®šï¼‰
        - å°‡ inf / -inf è½‰ç‚º nanï¼Œå†ä»¥ 0.0 å¡«è£œ
        - åˆªé™¤å…¨å¸¸æ•¸æ¬„ï¼ˆå° LGB/XGB ç­‰æ˜¯å®‰å…¨çš„ï¼›ä¸å½±éŸ¿ä½ ä¸‹æ¸¸äº’å‹•ï¼‰
        - ä¿ç•™è¼¸å‡ºèˆ‡äº’å‹•é¢¨æ ¼ï¼Œä¸é¡å¤–æ‰“å°
        """
        # è½‰ç‚º ndarray
        Xv = X.values if hasattr(X, "values") else X
        yv = y.values if hasattr(y, "values") else y

        Xv = np.asarray(Xv)
        yv = np.asarray(yv)

        # dtype è™•ç†
        if Xv.dtype != np.float32:
            Xv = Xv.astype(np.float32, copy=False)

        # ç„¡çª®å€¼ -> NaN -> 0
        Xv[~np.isfinite(Xv)] = np.nan
        # è‹¥æ•´åˆ—çš† NaNï¼ŒLightGBM æœƒè‡ªè¡Œå¿½ç•¥ï¼›é€™è£¡çµ±ä¸€å¡« 0ï¼Œé¿å…åˆ†ç®±å…¨ç©º
        nan_mask = np.isnan(Xv)
        if nan_mask.any():
            Xv[nan_mask] = 0.0

        # åˆªé™¤å…¨å¸¸æ•¸æ¬„ï¼ˆé˜²è³‡è¨Šæ´©æ¼ï¼›åŒæ™‚æ¸›å°‘åˆ†è£‚ç•°å¸¸ï¼‰
        if Xv.ndim == 2:
            col_max = np.nanmax(Xv, axis=0)
            col_min = np.nanmin(Xv, axis=0)
            const_cols = (col_max == col_min)
            if const_cols.any():
                Xv = Xv[:, ~const_cols]

        # y å‹åˆ¥
        if not np.issubdtype(yv.dtype, np.integer):
            # å¤šæ•¸åˆ†é¡æ¨™ç±¤å¯å®‰å…¨è½‰ int64
            try:
                yv = yv.astype(np.int64, copy=False)
            except Exception:
                # è‹¥ä¸å¯è½‰ï¼Œä¿ç•™åŸ dtype
                pass

        return Xv, yv
 